---
title: "制限ボルツマンマシンの基礎 ～微分編～"
emoji: "🤖"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Python","ML","BM","RBM"]
published: true
---

## はじめに

機械学習で用いられるボルツマンマシン、特に制限ボルツマンマシン(Restricted Boltzmann Machine, RBM)の解説その3です。[その2](https://zenn.dev/kaityo256/articles/boltzmann_machine2)の続きなので、そちらを見てから読んでください。

## 前回までのあらすじ

ぼっち飯のDaveは、いつも学食前のテラスでお弁当を食べていますが、同じクラスのAliceとBobが学食をよく利用していることに気づきます。しかし、AliceとBobは同時に現れることは少ないようです。AliceとBobは仲が悪いのでしょうか？

Daveは何日も二人を観測し、以下のようなデータを得ました。

そこでDaveは239日にわたって二人を観察し、AliceとBobが学食に来た日、来ていない日の統計を取りました。

|  A  |  B  | 日数|
| ---- | ---- |---|
|  x  | x  | 35|
|  x  |  o  |56|
|  o  |  x  |113|
|  o  |  o  |35|

Daveはさらに、この二人が「名前は知っているくらいで、特にお互い好きでも嫌いでもない」という情報から、「学食になんらかの隠れ変数があり、その変数を通じて二人が間接的に相互作用している」というモデルを作ります。Daveからは学食で何が起きているかわかりませんが、それでもパラメータを調節して、観測事実を再現できる確率モデルを構築しました。Daveが作ったモデルは、こんなエネルギーで表現されるモデルです。

$$
H(v_a, v_b, h_c) = -(b_a v_a+ b_b v_b+ b_c h_c + W_{ac}v_a h_c + W_{bc}v_b h_c)
$$

$v_a$、$v_b$は、それぞれAliceとBobが学食に来たか来なかったかを表す変数です。0か1の値を取り、学食に来たら1、そうでなければ0で表現します。これらはDaveから見える(visible)なので、可視変数と呼びます。

$h_c$は、学食で起きている「何か」を表す変数です。それが起きていたら1、起きていなければ0をとなります。実際にAliceとBobの行動に影響を与えていたのは「カレーフェア」でしたが、それをDaveは知りません。Daveからは隠れている(hidden)ので、隠れ変数と呼びます。

$b_a, b_b, b_c$はバイアスと呼ばれる量で、対応する変数の「1になりやすさ」を表しています。例えば$b_a$の値が大きいと、Aliceが学食に来る確率が高くなります。

$W_{ac}, W_{bc}$は重みと呼ばれる量で、対応する二つの変数の「同時に1になりやすさ」を表しています。例えば$W_{ac}$は「カレーフェア」が開催されているときにAliceが学食に来たがるかどうかを表現しています。正なら来る可能性が高くなり、負なら来る可能性が低くなります。添え字はどの変数とどの変数をつないでいるかを表現しており、これが「可視変数」と「隠れ変数」しかつないでいないモデルを制限ボルツマンマシン(Restricted Boltzmann Machine, RBM)と呼びます。

このモデルでは、三つの変数$(v_a, v_b, h_c)$で状態が指定できます。すると、その状態に対応するエネルギーが$H(v_a, v_b, h_c)$で与えられ、その状態の実現確率が$\exp(-H)$に比例すると考えるのがRBMによるモデリングです。