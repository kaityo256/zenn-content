---
title: "制限ボルツマンマシンの基礎 ～コスト関数編～"
emoji: "🤖"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Python","ML","BM","RBM"]
published: true
---

## はじめに

機械学習で用いられるボルツマンマシン、特に制限ボルツマンマシン(Restricted Boltzmann Machine, RBM)の解説その3です。[その2](https://zenn.dev/kaityo256/articles/boltzmann_machine2)の続きなので、そちらを見てから読んでください。

## 前回までのあらすじ

ぼっち飯のDaveは、いつも学食前のテラスでお弁当を食べていますが、同じクラスのAliceとBobが学食をよく利用していることに気づきます。しかし、AliceとBobは同時に現れることは少ないようです。AliceとBobは仲が悪いのでしょうか？

Daveは何日も二人を観測し、以下のようなデータを得ました。

そこでDaveは239日にわたって二人を観察し、AliceとBobが学食に来た日、来ていない日の統計を取りました。

|  A  |  B  | 日数|
| ---- | ---- |---|
|  x  | x  | 35|
|  x  |  o  |56|
|  o  |  x  |113|
|  o  |  o  |35|

Daveはさらに、この二人が「名前は知っているくらいで、特にお互い好きでも嫌いでもない」という情報から、「学食になんらかの隠れ変数があり、その変数を通じて二人が間接的に相互作用している」というモデルを作ります。Daveはこれが、制限ボルツマンマシンという、人工ニューラルネットワークモデルの一種であることを知ります。前回、全てのパラメータを気合で手で決定しましたが、適切なコスト関数を定義できれば、他のニューラルネットワークモデルと同様に最適化アルゴリズムによりパラメータを決めることができるはずです。

しかし、そこでDaveは悩みます。他のニューラルネットのコスト関数はわかる、でも制限ボルツマンマシンの学習のコスト関数とはなんだろう？そもそも制限ボルツマンマシンの学習とはどういうものだろう？

以下では、Daveの代わりにボルツマンマシンの学習について確認してみましょう。

## コスト関数

学習とは、多数のパラメータを持つモデルが、望ましい振る舞いをするようにパラメータを調整することです。その際、適当なコスト関数を定義し、そのコスト関数を最も小さくするようなパラメータを探す、最適化問題に落とすことがよく行われます。

例えばネコかイヌが写っている写真を見て、どちらが写っているか判定するAIを作りたいとしましょう。その場合、写真と正解ラベルのセットを大量に用意し、ニューラルネットワークに学習させ、学習に使っていない写真に対して正しく判定できたら学習がうまく行ったと判断できます。このように「入力データ」と「正解」がセットで与えられてるようなパターンの機械学習を教師あり学習(supervised learning)と呼びます。教師あり学習は、正解が離散的な分類問題と、正解が連続的な回帰問題に分けることができます。写真を見て何が写っているかを判定するのが分類問題、人が写っている写真を見て年齢を推定するのが回帰問題です。

このような教師あり学習においてコスト関数の定義は簡単です。例えば分類問題なら誤答率をコスト関数にすれば、コスト関数を最適化することが誤答を減らすことにつながり、結果として正しい分類器を得ることができます。回帰問題でも、正解とモデルの予測値の誤差の二乗か絶対値の和をコスト関数とすれば、コスト関数を下げれば下げるほど正解に近い、良いモデルができたことになります。

一方、ボルツマンマシンの学習では、入力データは与えますが、正解データはありません。ボルツマンマシンは入力データの「癖」を覚える確率マシンであり、何らかの正解率を上げたり、誤差率を減らしたりするものではありません。ではボルツマンマシンは何を学習しているのでしょうか？

## ボルツマンマシンが覚えるもの

たくさんのデータを与えると、ボルツマンマシンはそのデータの癖を覚えます。先程のAliceとBobの例なら、Aliceだけ、Bobだけが学食にくる確率に比べて、AliceとBobが同時に学食に来る確率が低いことを学びます。

ボルツマンマシンは確率モデルなので、問い合わせるたびに何か確率的な出力をします。